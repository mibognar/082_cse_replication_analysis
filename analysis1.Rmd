---
title: "analysis1"
author: "Miklos Bognar"
date: "2023-01-13"
output: html_document
---

# Load packages for this section
```{r message=F}
library(groundhog)
groundhog.day = "2023-09-13"
pkgs=c("tidyverse","papaja","lme4", "ggdist", "lmerTest", "emmeans", "ggeffects", "rstatix","BayesFactor", "jsonlite", "ez")
groundhog.library(pkgs,groundhog.day)
library(tidyverse)
library(papaja)
library(lme4)
library(ggdist)
library(lmerTest)
library(emmeans)
library(ggeffects)
library(rstatix)
library(BayesFactor)
library(jsonlite)
library(ez)
source("dienes_bayes.R")
```
### Cite all packages
```{r}
c("tidyverse","papaja","lme4", "ggdist", "lmerTest", "emmeans", "ggeffects", "rstatix","BayesFactor", "jsonlite", "ez")
citation()
citation("tidyverse")
citation("papaja")
citation("lme4")
citation("ggdist")
citation("lmerTest")
citation("emmeans")
citation("ggeffects")
citation("rstatix")
citation("BayesFactor")
citation("jsonlite")
citation("ez")
citation("groundhog")

```


# Loading source data
```{r}
hun_data = read_csv("data/hun_data.csv") %>% 
  mutate(site = "hungary") %>% 
  filter(participant_id != "participant_id")

it_data = read_csv("data/ita_data_fixed.csv") %>% 
  mutate(site = "italy")%>% 
  filter(participant_id != "participant_id")

sin_data = read_csv("data/sing_data_fixed.csv") %>% 
  mutate(site = "singapore") %>% 
  filter(participant_id != "participant_id")

source_data = rbind(hun_data,it_data, sin_data)
source_data = source_data %>% 
  group_by(participant_id) %>% 
  mutate(id = cur_group_id()) %>% 
  ungroup()

hun_data %>% 
  group_by(participant_id) %>%
  count() %>% 
  unique()

it_data %>% 
  group_by(participant_id) %>%
  count() %>% 
  unique()

sin_data %>% 
  group_by(participant_id) %>%
  count() %>% 
  unique()

source_data %>% 
  group_by(participant_id) %>%
  count() %>% 
  unique()
```


# Demographic analysis
---------------------------
```{r}

demographic = source_data %>% 
  filter(task == "survey") %>% 
  select(response,site) 

survey_data = purrr::map(demographic$response, jsonlite::fromJSON)
survey_data <- tibble(survey_data)  %>% 
  unnest_wider(survey_data)
survey_data = survey_data %>%
  mutate(sex = ifelse(nem %in% c("NÅ‘","Femmina","Female"), 1,0))

count(survey_data)
sum(survey_data$sex == 1)/count(survey_data)

demographic %>% 
  group_by(site) %>% 
  summarize(N = n())
```
## Anonimize dataframe
```{r}
raw_data = source_data %>% 
  filter(!(task %in% c("survey","consent")))

write_csv(raw_data,"data/zhang_replication_data.csv")
```

# Load anonimized data (START HERE)
```{r}
raw_data = read_csv("data/zhang_replication_data.csv")
```

# Prepare for sequential analysis
## Flag first trials in a block
```{r}
raw_data = raw_data %>% 
  mutate(first_trial = ifelse(lag(task,2) %in% c("pause_practice","pause"),1,0))
```

## Use only response data, exclude practice trials and first trials in every block
```{r}
raw_data = raw_data %>%
  filter(is.na(block)) %>%
  filter(task == "response")

all_response_data = raw_data
```

```{r}
nrow(all_response_data %>% filter(first_trial == 0)) / nrow(all_response_data) -1
```

```{r}
raw_data = raw_data %>% 
  filter(first_trial == 0)
```

## Check all the conditions with mean RT
```{r}
raw_data %>% 
  group_by(congruency) %>% 
  summarize(N = n(),
            mean_rt = mean(as.numeric(rt), na.rm = T),
            sd_rt = sd(as.numeric(rt), na.rm = T),
            se_rt = sd_rt/sqrt(N)) %>% 
  ungroup()
```

## Create previous trial data
```{r}
raw_data = raw_data %>% 
  arrange(participant_id, as.numeric(trial_index)) %>% 
  mutate(previous_rt = lag(rt),
         previous_congruency = lag(congruency),
         previous_correct = lag(correct))
  
```


## Count excluded trials
```{r}
nrow(raw_data %>% filter(correct==T, previous_correct ==T)) / nrow(raw_data) - 1
```


## Create rt and accuracy data
```{r}
raw_rt = raw_data %>% 
  filter(correct == T,
         previous_correct == T,
         previous_rt > 0)
```

```{r}
raw_accuracy = raw_data %>% 
  filter(previous_correct == T) %>% 
  mutate(acc = ifelse(correct==T, 1,0))
```

## Outlier detection
```{r}
rt_conditional_means = raw_rt %>% 
  group_by(id,congruency, previous_congruency) %>% 
  summarize(conditional_mean = mean(as.numeric(rt), na.rm = T),
            conditional_sd = sd(as.numeric(rt), na.rm=T))
  
raw_rt = raw_rt %>% 
  left_join(.,rt_conditional_means, by=c("id","congruency","previous_congruency"))


raw_rt = raw_rt %>% 
  mutate(rt = as.numeric(rt))

raw_rt = raw_rt %>% 
  mutate(rt_z = (rt-conditional_mean)/conditional_sd) %>% 
  mutate(drop_outlier = ifelse(abs(rt_z)>=3,1,0))


filtered_rt = raw_rt %>% 
  filter(drop_outlier == 0)

nrow(filtered_rt) / nrow(raw_rt) -1
```

```{r}
nrow(filtered_rt) / nrow(all_response_data) -1 
```
```{r}
nrow(filtered_rt %>% filter(site=="italy")) / nrow(all_response_data %>% filter(site=="italy")) -1 
```
```{r}
nrow(filtered_rt %>% filter(site=="singapore")) / nrow(all_response_data %>% filter(site=="singapore")) -1 
```
```{r}
nrow(filtered_rt %>% filter(site=="hungary")) / nrow(all_response_data %>% filter(site=="hungary")) -1 
```




# ANALYSIS

Original paper reaction times for different conflict levels
- NC = 708ms
- LC = 751ms
- HC = 767ms

mean congruency effect 29.5


## Create plot data
```{r}
cse_rt_data = filtered_rt %>% 
  group_by(congruency, previous_congruency) %>% 
  summarize(N = n(),
            mean_rt = mean(as.numeric(rt), na.rm = T),
            sd_rt = sd(rt, na.rm = T),
            se_rt = sd_rt/sqrt(N))
```
## Plot current + previous conditions RT
```{r}
cse_rt_plot = cse_rt_data %>% 
  ggplot()+
  aes(x=factor(previous_congruency, level=c("no_conflict","low_conflict", "high_conflict")), y=mean_rt, group=factor(congruency,level=c("no_conflict","low_conflict", "high_conflict")))+
  geom_point(size=1.5)+
  geom_path(size=1, aes(linetype=congruency))+
  
  #scale_shape_manual(values=c(17,16,15), labels=c("High-conflict","Low-conflict","No-conflict"))+
  scale_linetype_manual(values=c("solid", "dashed","dotted"), labels=c("High-conflict","Low-conflict","No-conflict"))+
  geom_errorbar(size=0.5,aes(ymin=mean_rt-se_rt,
                    ymax=mean_rt+se_rt,
                    width=.2))+
  papaja::theme_apa()+
  labs(x="Previous Congruency",
       y= "Reaction time (ms)",
       shape="Current Congruency",
       linetype="Current Congruency")+
  scale_x_discrete(labels = c("No-conflict","Low-conflict","High-conflict"))+
  theme(legend.key.width = unit(2,"cm"))




cse_rt_plot
ggsave("cse_plot.png",plot=cse_rt_plot, width = 1600, height = 900, units = "px", dpi = 200)
```
## Congruency effect plot data
```{r}
ce_rt_data = filtered_rt %>% 
  group_by(congruency) %>% 
  summarize(N = n(),
            mean_rt = mean(as.numeric(rt), na.rm = T),
            sd_rt = sd(rt, na.rm = T),
            se_rt = sd_rt/sqrt(N))


```
## Congruency effect plot
```{r}
cs_rt_plot = filtered_rt %>% 
  ggplot()+
  aes(x=factor(congruency, level=c("no_conflict","low_conflict", "high_conflict")),
      y=rt, 
      fill=factor(congruency, level=c("no_conflict","low_conflict", "high_conflict")),
      )+
  geom_boxplot(show.legend = F,
               width= .1,
               position= position_dodge2(padding = 10),
               outlier.colour = NA) +
  ggdist::stat_halfeye(
    adjust = .5,
    justification = -.2,
    .width = 0,
    width = .8,
    point_colour = NA,
    show.legend = F,
    position = position_dodge(width = 1)
  )+
  #geom_errorbar(size=.5,aes(ymin=mean_rt-se_rt,
                 #   ymax=mean_rt+se_rt,
                  #  width=.2))+
  papaja::theme_apa()+
  labs(x="Conflict level",
       y= "Reaction time (ms)")+
  scale_x_discrete(labels = c("No-conflict","Low-conflict","High-conflict")) +
  coord_cartesian(ylim = c(300,1000))+
  scale_fill_grey(
  start = 0.9,
  end = 0.3,
  na.value = "red",
  aesthetics = "fill",
  labels = c("NC","LC","HC"))
cs_rt_plot

ggsave("ce_plot.png",plot=cs_rt_plot, width = 1600, height = 900, units = "px", dpi = 200)
```

## Main congruency effect data
### Create main congruency labels
```{r}
filtered_rt = filtered_rt %>% 
  mutate(is_congruent = case_when(congruency %in% c("low_conflict","high_conflict") ~ 0,
                                  T ~ 1),
         is_prev_congruent = case_when(previous_congruency %in% c("low_conflict","high_conflict") ~ 0,
                                  T ~ 1))
```
### Coding conditions numerically for linear regression 
```{r}
filtered_rt = filtered_rt %>% 
  mutate(prev_num = case_when(previous_congruency == "no_conflict" ~ 0,
                              previous_congruency == "low_conflict" ~ 1,
                              TRUE ~ 2),
         current_num = case_when(congruency == "no_conflict" ~ 0,
                              congruency == "low_conflict" ~ 1,
                              TRUE ~ 2))
```

### Helmert contrast coding
```{r}
contrast_filtered_rt = filtered_rt %>% 
  mutate(congruency_helmert=as.factor(current_num),
         previous_congruency_helmert = as_factor(prev_num))
contrasts(contrast_filtered_rt$congruency_helmert) = contr.helmert(3)
contrasts(contrast_filtered_rt$previous_congruency_helmert) = contr.helmert(3)
```

### Create data by participant and by main congruency conditions
```{r}
subject_congruency_data = filtered_rt %>% 
  group_by(id, is_congruent) %>% 
  summarize(mean_rt = mean(rt, na.rm=T)) %>% 
  ungroup()
```
pivot for jasp
```{r}
subject_congruency_data_wide = subject_congruency_data %>% 
  pivot_wider(names_from = "is_congruent", values_from = "mean_rt")

write.csv(subject_congruency_data_wide, "data/subject_data_con.csv")
```

### Analyze with frequentist anova
```{r}
main_congruency_aov = anova_test(data = subject_congruency_data, formula = mean_rt ~ is_congruent  + Error(id/is_congruent))
main_congruency_aov
```
### Analyze with bayesian lmer
```{r}
main_congruency_model = lmer(rt ~ is_congruent + (1|id), data = contrast_filtered_rt)
mcm_summary = summary(main_congruency_model)
mcm_summary
```
```{r}
old_Bf(sd = mcm_summary$coefficients[4],
   obtained = mcm_summary$coefficients[2]*-1,
   dfdata = mcm_summary$coefficients[6],
   meanoftheory = 0,
   sdtheory =29.5,
   dftheory = 10^10,
   tail = 1)
```

robustness region
```{r}
h1_range = seq(from=3,to=4,by=.01)
range_test <- Bf_range(mcm_summary$coefficients[4], mcm_summary$coefficients[2]*-1,
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= h1_range,
tail=1, method = "new")
# find values for which BF > 3
ev_for_h1 <- subset(data.frame(range_test), BF > 3)
low_threshold_mcm <- min(ev_for_h1$sdtheory) # 3.46
high_threshold_mcm <- max(ev_for_h1$sdtheory) # 18546
```

```{r}
helmert_congruency_model = lmer(rt ~ congruency_helmert + (1|id), data = contrast_filtered_rt)
hcm_summary = summary(helmert_congruency_model)
hcm_summary
```

#### no-low BF
```{r}
old_Bf(sd = mcm_summary$coefficients[5],
   obtained = mcm_summary$coefficients[2],
   dfdata = mcm_summary$coefficients[8],
   meanoftheory = 0,
   sdtheory =29.5,
   dftheory = 10^10,
   tail = 1)

```
#### no-low RR
```{r}
h1_range = seq(from=0,to=1,by=.01)
range_test <- Bf_range(mcm_summary$coefficients[5], mcm_summary$coefficients[2],
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= h1_range,
tail=1, method = "new")
# find values for which BF > 3
ev_for_h1 <- subset(data.frame(range_test), BF > 3)
low_threshold_mcm <- min(ev_for_h1$sdtheory) # .98
high_threshold_mcm <- max(ev_for_h1$sdtheory) # 9066
```

#### low-high BF
```{r}
old_Bf(sd = mcm_summary$coefficients[6],
   obtained = mcm_summary$coefficients[3],
   dfdata = mcm_summary$coefficients[9],
   meanoftheory = 0,
   sdtheory =29.5,
   dftheory = 10^10,
   tail = 1)
```
#### low-high RR
```{r}
h1_range = seq(from=0.01, to=10,by=.01)
range_test <- Bf_range(mcm_summary$coefficients[6], mcm_summary$coefficients[3],
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= h1_range,
tail=1, method = "new")
# find values for which BF > 3
ev_for_h1 <- subset(data.frame(range_test), BF > 3)
low_threshold_mcm <- min(ev_for_h1$sdtheory) # .38
high_threshold_mcm <- max(ev_for_h1$sdtheory) # 5293
```


## Main Conflict Level Effect data
```{r}
subject_main_cl_data = filtered_rt %>% 
  group_by(id, congruency) %>% 
  summarize(mean_rt = mean(rt, na.rm=T)) %>% 
  ungroup()
```
### Analyze with frequentist anova
```{r}
main_cl_aov = anova_test(data = subject_main_cl_data, formula = mean_rt ~ congruency  + Error(id/(congruency)))
main_cl_aov
```



## Main Congruency Sequence Effect data
```{r}
subject_main_cse_data = filtered_rt %>% 
  group_by(id, is_congruent, is_prev_congruent) %>% 
  summarize(mean_rt = mean(rt, na.rm=T)) %>% 
  ungroup()
```
### Analyze with frequentist anova
```{r}
main_cse_aov = anova_test(data = subject_main_cse_data, formula = mean_rt ~ is_congruent*is_prev_congruent  + Error(id/(is_congruent*is_prev_congruent)))
main_cse_aov
```
### Analyze with bayesian lmer
```{r}
main_cse_model = lmer(rt ~ is_congruent*is_prev_congruent + (1|id), data = filtered_rt)
mcsem_summary = summary(main_cse_model)
mcsem_summary
anova(main_cse_model)
```
```{r}
{qqnorm(resid(main_cse_model))
qqline(resid(main_cse_model))}
```

### Bayes factor for interaction
```{r}
old_Bf(sd = mcsem_summary$coefficients[8],
   obtained = mcsem_summary$coefficients[4]*-1,
   dfdata = mcsem_summary$coefficients[12],
   meanoftheory = 0,
   sdtheory =29.5,
   dftheory = 10^10,
   tail = 1)
```


```{r}
Bf(sd = mcsem_summary$coefficients[8],
   obtained = mcsem_summary$coefficients[4]*-1,
   likelihood = "normal",
   modeloftheory= "normal",
   modeoftheory = 0,
   scaleoftheory = mcsem_summary$coefficients[1],
   tail = 1,
   method = "new")
```
### RR for interaction
```{r}
mcsem_low_range = seq(from=0.1,to=10,by=0.01)
mcsem_low_range_test <- Bf_range(mcsem_summary$coefficients[8], mcsem_summary$coefficients[4]*-1,
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= mcsem_low_range,
tail=1, method = "new")
# find values for which BF > 3
ev_low_for_mcsem <- subset(data.frame(mcsem_low_range_test), BF > 3)
low_threshold_mcsem <- min(ev_low_for_mcsem$sdtheory) #.18

mcsem_hi_range = seq(from=5000,to=15000,by=10)
mcsem_high_range_test <- Bf_range(mcsem_summary$coefficients[8], mcsem_summary$coefficients[4]*-1,
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= mcsem_hi_range,
tail=1, method = "new")
ev_high_for_mcsem <- subset(data.frame(mcsem_high_range_test), BF > 3)
high_threshold_mcsem <- max(ev_high_for_mcsem$sdtheory) #5670
```

## 3x3 interaction on conflict level
### Frequentist Anova
#### Create data by participant and by conditions
```{r}
subject_condition_data = filtered_rt %>% 
  group_by(id, congruency,previous_congruency) %>% 
  summarize(mean_rt = mean(rt, na.rm = T)) %>% 
  ungroup()
```
### #Create repeated measures formula and conduct anova
```{r}
freq_aov = anova_test(data = subject_condition_data, formula = mean_rt ~ congruency * previous_congruency + Error(id/(congruency * previous_congruency)))
freq_aov

```

### Same formula, different package
```{r}
ezANOVA(data=subject_condition_data, dv=mean_rt, wid=id, within = .(congruency,previous_congruency))
```


```{r}
three_interaction_model = lmer(rt ~ previous_congruency_helmert * congruency_helmert + (1|id), data=contrast_filtered_rt)
three_model = summary(three_interaction_model)
three_model

```

```{r}
ggemmeans(three_interaction_model,terms = c("previous_congruency_helmert","congruency_helmert"))  %>%  plot()
```
helmert 1*1 BF
```{r}
old_Bf(sd = three_model$coefficients[15],
   obtained = three_model$coefficients[6]*-1,
   dfdata = three_model$coefficients[24],
   meanoftheory = 0,
   sdtheory =14.75,
   dftheory = 10^10,
   tail = 2)
```
helmert 1*1 robustness region
```{r}
h1_range_3way_cse = seq(from=0,to=1,by=.01)
range_test_3way_cse <- Bf_range(three_model$coefficients[15], three_model$coefficients[6]*-1,
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= h1_range_3way_cse,
tail=2, method = "new")
# find values for which BF > 3
ev_for_h1_3way_cse <- subset(data.frame(range_test_3way_cse), BF > 3)
low_threshold_3way_cse <- min(ev_for_h1_3way_cse$sdtheory) #0.2
high_threshold_3way_cse <- max(ev_for_h1_3way_cse$sdtheory) #837
```

helmert 2*1 BF
```{r}
old_Bf(sd = three_model$coefficients[16],
   obtained = three_model$coefficients[7]*-1,
   dfdata = three_model$coefficients[25],
   meanoftheory = 0,
   sdtheory =14.75,
   dftheory = 10^10,
   tail = 2)
```
helmert 2*1 robustness region
```{r}
h1_range_3way_cse = seq(from=1,to=1000,by=1)
range_test_3way_cse <- Bf_range(three_model$coefficients[16], three_model$coefficients[7]*-1,
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= h1_range_3way_cse,
tail=2, method = "new")
# find values for which BF > 3
ev_for_h1_3way_cse <- subset(data.frame(range_test_3way_cse), BF > 3)
low_threshold_3way_cse <- min(ev_for_h1_3way_cse$sdtheory) #0.2
high_threshold_3way_cse <- max(ev_for_h1_3way_cse$sdtheory) #975
```

helmert 2*2 BF
```{r}
old_Bf(sd = three_model$coefficients[18],
   obtained = three_model$coefficients[9]*-1,
   dfdata = three_model$coefficients[27],
   meanoftheory = 0,
   sdtheory =14.75,
   dftheory = 10^10,
   tail = 2)
```
helmert 2*2 robustness region
```{r}
h1_range_3way_cse = seq(from=9,to=10,by=.01)
range_test_3way_cse <- Bf_range(three_model$coefficients[18], three_model$coefficients[9]*-1,
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= h1_range_3way_cse,
tail=2, method = "new")
# find values for which BF > 3
ev_for_h1_3way_cse <- subset(data.frame(range_test_3way_cse), BF < 3)
low_threshold_3way_cse <- min(ev_for_h1_3way_cse$sdtheory) #9.92
high_threshold_3way_cse <- max(ev_for_h1_3way_cse$sdtheory) #89
```

helmert 1*2 BF
```{r}
old_Bf(sd = three_model$coefficients[17],
   obtained = three_model$coefficients[8]*-1,
   dfdata = three_model$coefficients[26],
   meanoftheory = 0,
   sdtheory =14.75,
   dftheory = 10^10,
   tail = 2)
```
helmert 1*2 robustness region
```{r}
h1_range_3way_cse = seq(from=1,to=100000,by=100)
range_test_3way_cse <- Bf_range(three_model$coefficients[17], three_model$coefficients[8]*-1,
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= h1_range_3way_cse,
tail=2, method = "new")
# find values for which BF > 3
ev_for_h1_3way_cse <- subset(data.frame(range_test_3way_cse), BF < .33)
low_threshold_3way_cse <- min(ev_for_h1_3way_cse$sdtheory) #2.69
high_threshold_3way_cse <- max(ev_for_h1_3way_cse$sdtheory) # 99901
```


```{r}
print(low_threshold)
```

```{r}
print(high_threshold)
```

## 2x2 on LC and HC #2
```{r}
LC_HC_Hprev_subject_data = filtered_rt %>% 
  filter(current_num>0,
         prev_num>0) %>% 
  group_by(id, congruency,previous_congruency) %>% 
  summarize(mean_rt = mean(rt, na.rm = T)) %>% 
  ungroup()
```
```{r}
LC_HC_Hprev_anova = anova_test(data = LC_HC_Hprev_subject_data, formula = mean_rt ~ congruency * previous_congruency + Error(id/(congruency * previous_congruency)))
LC_HC_Hprev_anova
```
```{r}
LC_HC_Hprev_filtered_data = filtered_rt %>% 
  filter(current_num>0,
         prev_num>0) %>% 
  mutate(current_num = case_when(current_num>1 ~ 1,
                                 T ~ 0),
         prev_num = case_when(prev_num == 1 ~ 0,
                                 T ~ 1))
```

```{r}
LC_HC_Hprev_model = lmer(rt ~ prev_num * current_num + (1|id), data=LC_HC_Hprev_filtered_data)
LC_HC_H_model = summary(LC_HC_Hprev_model)
LC_HC_H_model
```
```{r}
old_Bf(sd = LC_HC_H_model$coefficients[8],
   obtained = LC_HC_H_model$coefficients[4],
   dfdata = LC_HC_H_model$coefficients[12],
   meanoftheory = 0,
   sdtheory =14.75,
   dftheory = 10^10,
   tail = 2)
```
```{r}
h1_range = seq(from=8,to=10,by=.01)
range_test <- Bf_range(LC_HC_H_model$coefficients[8], LC_HC_H_model$coefficients[4],
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= h1_range,
tail=2, method = "new")
# find values for which BF > 3
ev_for_h1 <- subset(data.frame(range_test), BF < .33)
low_threshold_3way_cse <- min(ev_for_h1$sdtheory) #8.96
high_threshold_3way_cse <- max(ev_for_h1$sdtheory) # inf
```

## 2x2 on LC and HC #1
```{r}
LC_HC_Lprev_subject_data = filtered_rt %>% 
  filter(current_num>0,
         prev_num<2) %>% 
  group_by(id, congruency,previous_congruency) %>% 
  summarize(mean_rt = mean(rt, na.rm = T)) %>% 
  ungroup()
```
```{r}
LC_HC_Lprev_anova = anova_test(data = LC_HC_Lprev_subject_data, formula = mean_rt ~ congruency * previous_congruency + Error(id/(congruency * previous_congruency)))
LC_HC_Lprev_anova
```
```{r}
LC_HC_Lprev_filtered_data = filtered_rt %>% 
  filter(current_num>0,
         prev_num<2) %>% 
  mutate(current_num = case_when(current_num>1 ~ 1,
                                 T ~ 0),
         prev_num = case_when(prev_num>0 ~ 1,
                                 T ~ 0))
```

```{r}
LC_HC_Lprev_model = lmer(rt ~ prev_num * current_num + (1|id), data=LC_HC_Lprev_filtered_data)
LC_HC_L_model = summary(LC_HC_Lprev_model)
LC_HC_L_model
```
```{r}
old_Bf(sd = LC_HC_L_model$coefficients[8],
   obtained = LC_HC_L_model$coefficients[4],
   dfdata = LC_HC_L_model$coefficients[12],
   meanoftheory = 0,
   sdtheory =14.75,
   dftheory = 10^10,
   tail = 2)
```
```{r}
h1_range = seq(from=10000,to=100000,by=1000)
range_test <- Bf_range(LC_HC_L_model$coefficients[8], LC_HC_L_model$coefficients[4],
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= h1_range,
tail=2, method = "new")
# find values for which BF > 3
ev_for_h1 <- subset(data.frame(range_test), BF < .33)
low_threshold_3way_cse <- min(ev_for_h1$sdtheory) #11.3
high_threshold_3way_cse <- max(ev_for_h1$sdtheory) # inf
```


## 2x3 interaction (LC-HC * NC-LC-HC)
### data for anova
```{r}
twobythree_interaction_subject_data = filtered_rt %>% 
  filter(prev_num>0) %>% 
  group_by(id, congruency,previous_congruency) %>% 
  summarize(mean_rt = mean(rt, na.rm = T)) %>% 
  ungroup()
```
### anova
```{r}
twobythree_anova = anova_test(data = twobythree_interaction_subject_data, formula = mean_rt ~ congruency * previous_congruency + Error(id/(congruency * previous_congruency)))
twobythree_anova
```

```{r}
crucial_model_data = filtered_rt %>% 
  filter(prev_num>0) %>% 
  mutate(prev_num = case_when(prev_num == 1 ~ 0,
                   T ~ 1))

crucial_model_summary = crucial_model_data %>% 
  group_by(prev_num, current_num) %>% 
  summarize(meanrt = mean(rt, na.rm=T))

crucial_numeric_interaction_model = lmer(rt ~ prev_num * current_num + (1|id), data=crucial_model_data)
summary(crucial_numeric_interaction_model)

crucial_numeric_model = summary(crucial_numeric_interaction_model)
crucial_numeric_model
```
### BF for crucial model
```{r}
old_Bf(sd = crucial_numeric_model$coefficients[8],
   obtained = crucial_numeric_model$coefficients[4]*-1,
   dfdata = crucial_numeric_model$coefficients[12],
   meanoftheory = 0,
   sdtheory =7.38,
   dftheory = 10^10,
   tail = 1)
```


```{r}
Bf(sd = crucial_numeric_model$coefficients[8], obtained = crucial_numeric_model$coefficients[4]*-1, likelihood = "normal",
modeloftheory= "normal", modeoftheory = 0,
scaleoftheory = crucial_numeric_model$coefficients[1], tail = 1, method = "new")
```
robustness region
```{r}
h1_range_twobythree_cse = seq(from=1000,to=10000,by=1)
range_test_twobythree_cse <- Bf_range(crucial_numeric_model$coefficients[8], crucial_numeric_model$coefficients[4]*-1,
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= h1_range_twobythree_cse,
tail=1, method = "new")
# find values for which BF > 3
twobythree_cse_ev_for_h1 <- subset(data.frame(range_test_twobythree_cse), BF > 3)
crucial_low_threshold <- min(twobythree_cse_ev_for_h1$sdtheory)#0.4
crucial_high_threshold <- max(twobythree_cse_ev_for_h1$sdtheory) #1877
```

## Increasing the level of conflict leads to conflict adaptation
```{r}
increased_conflict_data = filtered_rt %>% 
  filter(previous_congruency %in% c("low_conflict","high_conflict"))

increased_conflict_data_means = filtered_rt %>% 
   group_by(is_congruent, previous_congruency) %>% 
  summarize(N = n(),
            mean_rt = mean(as.numeric(rt), na.rm = T),
            sd_rt = sd(rt, na.rm = T),
            se_rt = sd_rt/sqrt(N))

increased_conflict_data_means_plot = increased_conflict_data_means %>% 
  ggplot()+
  aes(x=factor(previous_congruency, levels = c("no_conflict","low_conflict","high_conflict")), y=mean_rt, color=as.factor(is_congruent), group=as.factor(is_congruent))+
  geom_point(size=2)+
  geom_path(size=1)+
  geom_errorbar(size=1,aes(ymin=mean_rt-se_rt,
                    ymax=mean_rt+se_rt,
                    width=.2))+
  papaja::theme_apa()+
  labs(x="Previous Congruency",
       y= "Reaction time",
       color="Current Congruency",
       title="Pilot CSE plot")

increased_conflict_data_means_plot
```
### anova data for congruency on low-high
```{r}
subject_data_congruency_by_two = filtered_rt %>% 
  group_by(id, is_congruent, previous_congruency) %>% 
  summarize(N = n(),
            mean_rt = mean(as.numeric(rt), na.rm = T)) %>% 
  ungroup()
```
### anova for congruency on low-high
```{r}
congruency_by_two_anova = anova_test(data = subject_data_congruency_by_two, formula = mean_rt ~is_congruent * previous_congruency + Error(id/(is_congruent * previous_congruency)))
congruency_by_two_anova
```
### lmer for same model
```{r}
congruency_by_two_model = lmer(rt ~ previous_congruency_helmert * is_congruent + (1|id), data=contrast_filtered_rt)
cbt_model = summary(congruency_by_two_model)
cbt_model
```
#### prev1*congruency BF
```{r}
old_Bf(sd = cbt_model$coefficients[11],
   obtained = cbt_model$coefficients[5],
   dfdata = cbt_model$coefficients[17],
   meanoftheory = 0,
   sdtheory =14.75,
   dftheory = 10^10,
   tail = 1)

```
#### prev1*congruency Robustness region
```{r}
h1_range_bytwo = seq(from=.01,to=1,by=.01)
range_test_bytwo <- Bf_range(cbt_model$coefficients[11], cbt_model$coefficients[5],
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= h1_range_bytwo,
tail=1, method = "new")
# find values for which BF > 3
bytwo_cse_ev_for_h1 <- subset(data.frame(range_test_bytwo), BF > 3)
bytwo_low_threshold <- min(bytwo_cse_ev_for_h1$sdtheory)#0.2
bytwo_high_threshold <- max(bytwo_cse_ev_for_h1$sdtheory) #1698
```


#### prev2*congruency BF
```{r}
old_Bf(sd = cbt_model$coefficients[12],
   obtained = cbt_model$coefficients[6],
   dfdata = cbt_model$coefficients[18],
   meanoftheory = 0,
   sdtheory =14.75,
   dftheory = 10^10,
   tail = 1)

```
#### prev2*congruency Robustness region
```{r}
h1_range_bytwo = seq(from=0,to=1,by=.01)
range_test_bytwo <- Bf_range(cbt_model$coefficients[12], cbt_model$coefficients[6],
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= h1_range_bytwo,
tail=1, method = "new")
# find values for which BF > 3
bytwo_cse_ev_for_h1 <- subset(data.frame(range_test_bytwo), BF > 3)
bytwo_low_threshold <- min(bytwo_cse_ev_for_h1$sdtheory)#0.08
bytwo_high_threshold <- max(bytwo_cse_ev_for_h1$sdtheory) #1853
```

## exploratory 2x2 on lohi-lohi
```{r}
lohi_subject_data = filtered_rt %>% 
  filter(prev_num>0,
         current_num>0) %>% 
  group_by(id, congruency,previous_congruency) %>% 
  summarize(mean_rt = mean(rt, na.rm = T)) %>% 
  ungroup()
```
### lohi anova
```{r}
lohi_anova = anova_test(data = lohi_subject_data, formula = mean_rt ~ congruency * previous_congruency + Error(id/(congruency * previous_congruency)))
lohi_anova
```

### lohi model data
```{r}
lohi_model_data = filtered_rt %>% 
  filter(prev_num>0,
         current_num>0) %>% 
  mutate(prev_num = case_when(prev_num == 1 ~ 0,
                   T ~ 1),
         current_num = case_when(current_num == 1 ~ 0,
                   T ~ 1)
         )
```

```{r}
lohi_interaction_model = lmer(rt ~ prev_num * current_num + (1|id), data=lohi_model_data)
lohi_model = summary(lohi_interaction_model)
lohi_model
```
```{r}
Bf(sd = lohi_model$coefficients[8], obtained = lohi_model$coefficients[4], likelihood = "normal",
modeloftheory= "normal", meanoftheory = 0,
scaleoftheory = 14.75, tail = 1, method = "new")
```
```{r}
old_Bf(sd = lohi_model$coefficients[8],
   obtained = lohi_model$coefficients[4],
   dfdata = lohi_model$coefficients[12],
   meanoftheory = 0,
   sdtheory =14.75,#9.7,
   dftheory = 10^10,
   tail = 1)

```


```{r}
loh_range = seq(from=1,to=10000,by=1)
range_test_lohi <- Bf_range(lohi_model$coefficients[8], lohi_model$coefficients[4],
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= loh_range,
tail=1, method = "new")
# find values for which BF > 3
bytwo_cse_ev_for_h1 <- subset(data.frame(range_test_bytwo), BF > 3)
bytwo_low_threshold <- min(bytwo_cse_ev_for_h1$sdtheory)#0.55
bytwo_high_threshold <- max(bytwo_cse_ev_for_h1$sdtheory) #3078
```





# General CSE plot
```{r}
cse_rt_data_no_levels = conflict_level_data %>% 
  group_by(is_congruent, is_prev_congruent) %>% 
  summarize(N = n(),
            mean_rt = mean(as.numeric(rt), na.rm = T),
            sd_rt = sd(rt, na.rm = T),
            se_rt = sd_rt/sqrt(N))

cse_rt_data_no_levels_plot = cse_rt_data_no_levels %>% 
  ggplot()+
  aes(x=as.factor(is_prev_congruent), y=mean_rt, color=as.factor(is_congruent), group=as.factor(is_congruent))+
  geom_point(size=2)+
  geom_path(size=1)+
  geom_errorbar(size=1,aes(ymin=mean_rt-se_rt,
                    ymax=mean_rt+se_rt,
                    width=.2))+
  papaja::theme_apa()+
  labs(x="Previous Congruency",
       y= "Reaction time",
       color="Current Congruency",
       title="Pilot CSE plot")

cse_rt_data_no_levels_plot
```


# Accuracy analysis with plot
```{r}
cse_acc_data = raw_accuracy %>% 
  group_by(congruency, previous_congruency) %>% 
  summarize(N = n(),
            mean_acc = mean(acc, na.rm = T),
            error_rate = 1-mean_acc,
            sd_acc = sd(acc, na.rm = T),
            se_acc = sd_acc/sqrt(N))
```
```{r}
cse_acc_plot = cse_acc_data %>% 
  ggplot()+
  aes(x=factor(previous_congruency, level=c("no_conflict","low_conflict","high_conflict")), y=error_rate, color=congruency, group=congruency)+
  geom_point(size=2)+
  geom_path(size=1)+
  geom_errorbar(size=1,aes(ymin=error_rate-se_acc,
                    ymax=error_rate+se_acc,
                    width=.2))+
  papaja::theme_apa()+
  labs(x="Previous Congruency",
       y= "Mean error_rate",
       color="Current Congruency",
       title="Pilot CSE plot - Accuracy")



cse_acc_plot
```
```{r}
mymodel_acc = lmer(acc ~ congruency * previous_congruency + (1|id), data=raw_accuracy)

summary(mymodel_acc)
anova(mymodel_acc)

reduced_model = lmer(acc ~ congruency + previous_congruency + (1|id), data = raw_accuracy)
anova(reduced_model)

anova(reduced_model,mymodel_acc)

bayesfactor_models(reduced_model, mymodel_acc)
```
```{r}
pairwise_t_test(filter(raw_accuracy, congruency=="low_conflict"), acc ~ previous_congruency, p.adjust.method = "bonferroni")
pairwise_t_test(filter(raw_accuracy, congruency=="no_conflict"), acc ~ previous_congruency, p.adjust.method = "bonferroni")
```