---
title: "analysis1"
author: "Miklos Bognar"
date: "2023-01-13"
output: html_document
---

# Load packages for this section
```{r message=F}
library(tidyverse)
library(papaja)
library(lme4)
library(lmerTest)
library(rstatix)
library(BayesFactor)
library(jsonlite)
library(ez)
source("dienes_bayes.R")
```

# Loading source data
```{r}
hun_data = read_csv("data/hun_data.csv") %>% 
  mutate(site = "hungary")
it_data = read_csv("data/ita_data_fixed.csv") %>% 
  mutate(site = "italy")
sin_data = read_csv("data/sing_data_fixed.csv") %>% 
  mutate(site = "singapore")

source_data = rbind(hun_data,it_data, sin_data)
source_data = source_data %>% 
  group_by(participant_id) %>% 
  mutate(id = cur_group_id()) %>% 
  ungroup()

source_data %>% 
  group_by(id,site) %>%
  count() %>% 
  unique()
```


# Demographic analysis
---------------------------
```{r}

demographic = source_data %>% 
  filter(task == "survey") %>% 
  select(response,site) 

survey_data = purrr::map(demographic$response, jsonlite::fromJSON)
survey_data <- tibble(survey_data)  %>% 
  unnest_wider(survey_data)
survey_data = survey_data %>%
  mutate(sex = ifelse(nem %in% c("NÅ‘","Femmina","Female"), 1,0))

count(survey_data)
sum(survey_data$sex == 1)/count(survey_data)

demographic %>% 
  group_by(site) %>% 
  summarize(N = n())
```
## Anonimize dataframe
```{r}
raw_data = source_data %>% 
  filter(!(task %in% c("survey","consent")))

write_csv(raw_data,"data/zhang_replication_data.csv")
```

# Load anonimized data (START HERE)
```{r}
raw_data = read_csv("data/zhang_replication_data.csv")
```

# Prepare for sequential analysis
## Flag first trials in a block
```{r}
raw_data = raw_data %>% 
  mutate(first_trial = ifelse(lag(task,2) %in% c("pause_practice","pause"),1,0))
```

## Use only response data, exclude practice trials and first trials in every block
```{r}
raw_data = raw_data %>%
  filter(is.na(block)) %>%
  filter(task == "response")

all_response_data = raw_data
```

```{r}
nrow(all_response_data %>% filter(first_trial == 0)) / nrow(all_response_data) -1
```

```{r}
raw_data = raw_data %>% 
  filter(first_trial == 0)
```

## Check all the conditions with mean RT
```{r}
raw_data %>% 
  group_by(congruency) %>% 
  summarize(N = n(),
            mean_rt = mean(as.numeric(rt), na.rm = T),
            sd_rt = sd(as.numeric(rt), na.rm = T),
            se_rt = sd_rt/sqrt(N)) %>% 
  ungroup()
```

## Create previous trial data
```{r}
raw_data = raw_data %>% 
  arrange(participant_id, as.numeric(trial_index)) %>% 
  mutate(previous_rt = lag(rt),
         previous_congruency = lag(congruency),
         previous_correct = lag(correct))
  
```


## Count excluded trials
```{r}
nrow(raw_data %>% filter(correct==T, previous_correct ==T)) / nrow(raw_data) - 1
```


## Create rt and accuracy data
```{r}
raw_rt = raw_data %>% 
  filter(correct == T,
         previous_correct == T,
         previous_rt > 0)
```

```{r}
raw_accuracy = raw_data %>% 
  filter(previous_correct == T) %>% 
  mutate(acc = ifelse(correct==T, 1,0))
```

## Outlier detection
```{r}
rt_conditional_means = raw_rt %>% 
  group_by(id,congruency, previous_congruency) %>% 
  summarize(conditional_mean = mean(as.numeric(rt), na.rm = T),
            conditional_sd = sd(as.numeric(rt), na.rm=T))
  
raw_rt = raw_rt %>% 
  left_join(.,rt_conditional_means, by=c("id","congruency","previous_congruency"))


raw_rt = raw_rt %>% 
  mutate(rt = as.numeric(rt))

raw_rt = raw_rt %>% 
  mutate(rt_z = (rt-conditional_mean)/conditional_sd) %>% 
  mutate(drop_outlier = ifelse(abs(rt_z)>=3,1,0))


filtered_rt = raw_rt %>% 
  filter(drop_outlier == 0)

nrow(filtered_rt) / nrow(raw_rt) -1
```
```{r}
nrow(filtered_rt) / nrow(all_response_data) -1 
```

# ANALYSIS

Original reaction times for different conflict levels
- NC = 708ms
- LC = 751ms
- HC = 767ms

mean congruency effect 29.5


## Create plot data
```{r}
cse_rt_data = filtered_rt %>% 
  group_by(congruency, previous_congruency) %>% 
  summarize(N = n(),
            mean_rt = mean(as.numeric(rt), na.rm = T),
            sd_rt = sd(rt, na.rm = T),
            se_rt = sd_rt/sqrt(N))
```
## Plot current + previous conditions RT
```{r}
cse_rt_plot = cse_rt_data %>% 
  ggplot()+
  aes(x=factor(previous_congruency, level=c("no_conflict","low_conflict", "high_conflict")), y=mean_rt, group=congruency)+
  geom_point(size=3, aes(shape=congruency))+
  geom_path(size=1, aes(linetype=congruency))+
  scale_shape_manual(values=c(17,16,15), labels=c("NC","LC","HC"))+
  scale_linetype_manual(values=c("solid", "dashed","dotted"), labels=c("NC","LC","HC"))+
  geom_errorbar(size=1,aes(ymin=mean_rt-se_rt,
                    ymax=mean_rt+se_rt,
                    width=.2))+
  papaja::theme_apa()+
  labs(x="Previous Congruency",
       y= "Reaction time (ms)",
       shape="Current Congruency",
       linetype="Current Congruency")+
  scale_x_discrete(labels = c("NC","LC","HC"))




cse_rt_plot
ggsave("cse_plot.png",plot=cse_rt_plot, width = 1600, height = 900, units = "px", dpi = 200)
```
## Congruency effect plot data
```{r}
ce_rt_data = filtered_rt %>% 
  group_by(congruency) %>% 
  summarize(N = n(),
            mean_rt = mean(as.numeric(rt), na.rm = T),
            sd_rt = sd(rt, na.rm = T),
            se_rt = sd_rt/sqrt(N))


```
## Congruency effect plot
```{r}
cs_rt_plot = ce_rt_data %>% 
  ggplot()+
  geom_col(width = 0.5)+
  aes(x=factor(congruency, level=c("no_conflict","low_conflict", "high_conflict")), y=mean_rt, fill=congruency)+
  geom_errorbar(size=.5,aes(ymin=mean_rt-se_rt,
                    ymax=mean_rt+se_rt,
                    width=.2))+
  papaja::theme_apa()+
  labs(x="Congruency",
       y= "Reaction time (ms)",
       fill = "Congruency")+
  scale_x_discrete(labels = c("NC","LC","HC")) +
  coord_cartesian(ylim = c(620,750))+
  scale_fill_grey(
  start = 0.2,
  end = 0.8,
  na.value = "red",
  aesthetics = "fill",
  labels = c("NC","LC","HC")
)

cs_rt_plot
ggsave("ce_plot.png",plot=cs_rt_plot, width = 1600, height = 900, units = "px", dpi = 200)
```

## Main congruency effect data
### Create main congruency labels
```{r}
filtered_rt = filtered_rt %>% 
  mutate(is_congruent = case_when(congruency %in% c("low_conflict","high_conflict") ~ 0,
                                  T ~ 1),
         is_prev_congruent = case_when(previous_congruency %in% c("low_conflict","high_conflict") ~ 0,
                                  T ~ 1))
```
### Coding conditions numerically for linear regression 
```{r}
filtered_rt = filtered_rt %>% 
  mutate(prev_num = case_when(previous_congruency == "no_conflict" ~ 0,
                              previous_congruency == "low_conflict" ~ 1,
                              TRUE ~ 2),
         current_num = case_when(congruency == "no_conflict" ~ 0,
                              congruency == "low_conflict" ~ 1,
                              TRUE ~ 2))
```

### Create data by participant and by main congruency conditions
```{r}
subject_congruency_data = filtered_rt %>% 
  group_by(id, is_congruent) %>% 
  summarize(mean_rt = mean(rt, na.rm=T)) %>% 
  ungroup()
```
### Analyze with frequentist anova
```{r}
main_congruency_aov = anova_test(data = subject_congruency_data, formula = mean_rt ~ is_congruent  + Error(id/is_congruent))
main_congruency_aov
```
### Analyze with bayesian lmer
```{r}
main_congruency_model = lmer(rt ~ is_congruent + (1+is_congruent|id), data = filtered_rt)
mcm_summary = summary(main_congruency_model)
mcm_summary
```
```{r}
{qqnorm(resid(main_congruency_model))
qqline(resid(main_congruency_model))}
```

```{r}
old_Bf(sd = mcm_summary$coefficients[4],
   obtained = mcm_summary$coefficients[2]*-1,
   dfdata = mcm_summary$coefficients[6],
   meanoftheory = 0,
   sdtheory =29.5,
   dftheory = 10^10,
   tail = 1)

```


```{r}
Bf(sd = mcm_summary$coefficients[4], obtained = mcm_summary$coefficients[2]*-1, likelihood = "normal",
modeloftheory= "normal", modeoftheory = 0,
scaleoftheory = mcm_summary$coefficients[1], tail = 1, method = "new")
```
robustness region
```{r}
h1_range = seq(from=18501,to=18601,by=1)
range_test <- Bf_range(mcm_summary$coefficients[4], mcm_summary$coefficients[2]*-1,
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= h1_range,
tail=1, method = "new")
# find values for which BF > 3
ev_for_h1 <- subset(data.frame(range_test), BF > 3)
low_threshold_mcm <- min(ev_for_h1$sdtheory) # 3.46
high_threshold_mcm <- max(ev_for_h1$sdtheory) # 18546
```
## Main Conflict Level Effect data
```{r}
subject_main_cl_data = filtered_rt %>% 
  group_by(id, congruency) %>% 
  summarize(mean_rt = mean(rt, na.rm=T)) %>% 
  ungroup()
```
### Analyze with frequentist anova
```{r}
main_cl_aov = anova_test(data = subject_main_cl_data, formula = mean_rt ~ congruency  + Error(id/(congruency)))
main_cl_aov
```

### Analyze with bayesian lmer
```{r}
main_cl_model = lmer(rt ~ current_num + (1|id), data = filtered_rt)
main_cl_summary = summary(main_cl_model)
main_cl_summary
```

```{r}
old_Bf(sd = main_cl_summary$coefficients[4],
   obtained = main_cl_summary$coefficients[2],
   dfdata = main_cl_summary$coefficients[6],
   meanoftheory = 0,
   sdtheory = 29.5,
   dftheory = 10^10,
   tail = 1)
```
```{r}
mclm_low_range = seq(from=0.01,to=10,by=0.01)
mclm_low_range_test <- Bf_range(main_cl_summary$coefficients[4], main_cl_summary$coefficients[2],
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= mclm_low_range,
tail=1, method = "new")
# find values for which BF > 3
ev_low_for_mclm <- subset(data.frame(mclm_low_range_test), BF > 3)
low_threshold_mcsem <- min(ev_low_for_mclm$sdtheory) #2.05
```

```{r}
mclm_hi_range = seq(from=10000,to=13000,by=1)
mclm_hi_range_test <- Bf_range(main_cl_summary$coefficients[4], main_cl_summary$coefficients[2],
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= mclm_hi_range,
tail=1, method = "new")
# find values for which BF > 3
ev_hi_for_mclm <- subset(data.frame(mclm_hi_range_test), BF > 3)
hi_threshold_mcsem <- max(ev_hi_for_mclm$sdtheory) #11109
```


```{r}
Bf(sd = main_cl_summary$coefficients[4], obtained = main_cl_summary$coefficients[2], likelihood = "normal",
modeloftheory= "normal", modeoftheory = 0,
scaleoftheory = main_cl_summary$coefficients[1], tail = 1, method = "new")
```

## Main Congruency Sequence Effect data
```{r}
subject_main_cse_data = filtered_rt %>% 
  group_by(id, is_congruent, is_prev_congruent) %>% 
  summarize(mean_rt = mean(rt, na.rm=T)) %>% 
  ungroup()
```
### Analyze with frequentist anova
```{r}
main_cse_aov = anova_test(data = subject_main_cse_data, formula = mean_rt ~ is_congruent*is_prev_congruent  + Error(id/(is_congruent*is_prev_congruent)))
main_cse_aov
```
### Analyze with bayesian lmer
```{r}
main_cse_model = lmer(rt ~ is_congruent*is_prev_congruent + (1|id), data = filtered_rt)
mcsem_summary = summary(main_cse_model)
mcsem_summary
```
```{r}
{qqnorm(resid(main_cse_model))
qqline(resid(main_cse_model))}
```

### Bayes factor for interaction
```{r}
old_Bf(sd = mcsem_summary$coefficients[8],
   obtained = mcsem_summary$coefficients[4]*-1,
   dfdata = mcsem_summary$coefficients[12],
   meanoftheory = 0,
   sdtheory =14.75,
   dftheory = 10^10,
   tail = 1)
```


```{r}
Bf(sd = mcsem_summary$coefficients[8],
   obtained = mcsem_summary$coefficients[4]*-1,
   likelihood = "normal",
   modeloftheory= "normal",
   modeoftheory = 0,
   scaleoftheory = mcsem_summary$coefficients[1],
   tail = 1,
   method = "new")
```
### RR for interaction
```{r}
mcsem_low_range = seq(from=0.1,to=10,by=0.01)
mcsem_low_range_test <- Bf_range(mcsem_summary$coefficients[8], mcsem_summary$coefficients[4]*-1,
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= mcsem_low_range,
tail=1, method = "new")
# find values for which BF > 3
ev_low_for_mcsem <- subset(data.frame(mcsem_low_range_test), BF > 3)
low_threshold_mcsem <- min(ev_low_for_mcsem$sdtheory) #.18

mcsem_hi_range = seq(from=5000,to=15000,by=10)
mcsem_high_range_test <- Bf_range(mcsem_summary$coefficients[8], mcsem_summary$coefficients[4]*-1,
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= mcsem_hi_range,
tail=1, method = "new")
ev_high_for_mcsem <- subset(data.frame(mcsem_high_range_test), BF > 3)
high_threshold_mcsem <- max(ev_high_for_mcsem$sdtheory) #5670
```

## 3x3 interaction on conflict level
### Frequentist Anova
#### Create data by participant and by conditions
```{r}
subject_condition_data = filtered_rt %>% 
  group_by(id, congruency,previous_congruency) %>% 
  summarize(mean_rt = mean(rt, na.rm = T)) %>% 
  ungroup()
```
### #Create repeated measures formula and conduct anova
```{r}
freq_aov = anova_test(data = subject_condition_data, formula = mean_rt ~ congruency * previous_congruency + Error(id/(congruency * previous_congruency)))
freq_aov

```

### Same formula, different package
```{r}
ezANOVA(data=subject_condition_data, dv=mean_rt, wid=id, within = .(congruency,previous_congruency))
```


```{r}
numeric_interaction_model = lmer(rt ~ prev_num * current_num + (1|id), data=filtered_rt)
numeric_model = summary(numeric_interaction_model)
numeric_model
```

```{r}
old_Bf(sd = numeric_model$coefficients[8],
   obtained = numeric_model$coefficients[4]*-1,
   dfdata = numeric_model$coefficients[12],
   meanoftheory = 0,
   sdtheory =7.38,
   dftheory = 10^10,
   tail = 1)
```

```{r}
Bf(sd = numeric_model$coefficients[8], obtained = numeric_model$coefficients[4]*-1, likelihood = "normal",
modeloftheory= "normal", modeoftheory = 0,
scaleoftheory = numeric_model$coefficients[1], tail = 1, method = "new")
```

```{r}
{qqnorm(resid(numeric_interaction_model))
qqline(resid(numeric_interaction_model))}
```

robustness region
```{r}
h1_range_3way_cse = seq(from=0.01,to=0.1,by=0.01)
range_test_3way_cse <- Bf_range(numeric_model$coefficients[8], numeric_model$coefficients[4]*-1,
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= h1_range_3way_cse,
tail=1, method = "new")
# find values for which BF > 3
ev_for_h1_3way_cse <- subset(data.frame(range_test_3way_cse), BF > 3)
low_threshold_3way_cse <- min(ev_for_h1_3way_cse$sdtheory) #0.07
high_threshold_3way_cse <- max(ev_for_h1_3way_cse$sdtheory) #1996
```


```{r}
print(low_threshold)
```

```{r}
print(high_threshold)
```

## 2x3 interaction (LC-HC * NC-LC-HC)
### data for anova
```{r}
twobythree_interaction_subject_data = filtered_rt %>% 
  filter(prev_num>0) %>% 
  group_by(id, congruency,previous_congruency) %>% 
  summarize(mean_rt = mean(rt, na.rm = T)) %>% 
  ungroup()
```
### anova
```{r}
twobythree_anova = anova_test(data = twobythree_interaction_subject_data, formula = mean_rt ~ congruency * previous_congruency + Error(id/(congruency * previous_congruency)))
twobythree_anova
```

```{r}
crucial_model_data = filtered_rt %>% 
  filter(prev_num>0) %>% 
  mutate(prev_num = case_when(prev_num == 1 ~ 0,
                   T ~ 1))

crucial_model_summary = crucial_model_data %>% 
  group_by(prev_num, current_num) %>% 
  summarize(meanrt = mean(rt, na.rm=T))

crucial_numeric_interaction_model = lmer(rt ~ prev_num * current_num + (1|id), data=crucial_model_data)
summary(crucial_numeric_interaction_model)

crucial_numeric_model = summary(crucial_numeric_interaction_model)
crucial_numeric_model
```
### BF for crucial model
```{r}
old_Bf(sd = crucial_numeric_model$coefficients[8],
   obtained = crucial_numeric_model$coefficients[4]*-1,
   dfdata = crucial_numeric_model$coefficients[12],
   meanoftheory = 0,
   sdtheory =7.38,
   dftheory = 10^10,
   tail = 1)
```


```{r}
Bf(sd = crucial_numeric_model$coefficients[8], obtained = crucial_numeric_model$coefficients[4]*-1, likelihood = "normal",
modeloftheory= "normal", modeoftheory = 0,
scaleoftheory = crucial_numeric_model$coefficients[1], tail = 1, method = "new")
```
robustness region
```{r}
h1_range_twobythree_cse = seq(from=1000,to=10000,by=1)
range_test_twobythree_cse <- Bf_range(crucial_numeric_model$coefficients[8], crucial_numeric_model$coefficients[4]*-1,
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= h1_range_twobythree_cse,
tail=1, method = "new")
# find values for which BF > 3
twobythree_cse_ev_for_h1 <- subset(data.frame(range_test_twobythree_cse), BF > 3)
crucial_low_threshold <- min(twobythree_cse_ev_for_h1$sdtheory)#0.4
crucial_high_threshold <- max(twobythree_cse_ev_for_h1$sdtheory) #1877
```

## Increasing the level of conflict leads to conflict adaptation
```{r}
increased_conflict_data = filtered_rt %>% 
  filter(previous_congruency %in% c("low_conflict","high_conflict"))

increased_conflict_data_means = increased_conflict_data %>% 
   group_by(is_congruent, previous_congruency) %>% 
  summarize(N = n(),
            mean_rt = mean(as.numeric(rt), na.rm = T),
            sd_rt = sd(rt, na.rm = T),
            se_rt = sd_rt/sqrt(N))

increased_conflict_data_means_plot = increased_conflict_data_means %>% 
  ggplot()+
  aes(x=factor(previous_congruency, levels = c("low_conflict","high_conflict")), y=mean_rt, color=as.factor(is_congruent), group=as.factor(is_congruent))+
  geom_point(size=2)+
  geom_path(size=1)+
  geom_errorbar(size=1,aes(ymin=mean_rt-se_rt,
                    ymax=mean_rt+se_rt,
                    width=.2))+
  papaja::theme_apa()+
  labs(x="Previous Congruency",
       y= "Reaction time",
       color="Current Congruency",
       title="Pilot CSE plot")

increased_conflict_data_means_plot
```
### anova data for congruency on low-high
```{r}
subject_data_congruency_by_two = increased_conflict_data %>% 
  group_by(id, is_congruent, previous_congruency) %>% 
  summarize(N = n(),
            mean_rt = mean(as.numeric(rt), na.rm = T)) %>% 
  ungroup()
```
### anova for congruency on low-high
```{r}
congruency_by_two_anova = anova_test(data = subject_data_congruency_by_two, formula = mean_rt ~is_congruent * previous_congruency + Error(id/(is_congruent * previous_congruency)))
congruency_by_two_anova
```
### lmer for same model
```{r}
congruency_by_two_model = lmer(rt ~ prev_num * is_congruent + (1|id), data=increased_conflict_data)
cbt_model = summary(congruency_by_two_model)
cbt_model
```

```{r}
old_Bf(sd = cbt_model$coefficients[8],
   obtained = cbt_model$coefficients[4],
   dfdata = cbt_model$coefficients[12],
   meanoftheory = 0,
   sdtheory =14.75,
   dftheory = 10^10,
   tail = 1)

```
### Robustness region
```{r}
h1_range_bytwo = seq(from=0.01,to=1,by=0.01)
range_test_bytwo <- Bf_range(cbt_model$coefficients[8], cbt_model$coefficients[4],
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= h1_range_bytwo,
tail=1, method = "new")
# find values for which BF > 3
bytwo_cse_ev_for_h1 <- subset(data.frame(range_test_bytwo), BF > 3)
bytwo_low_threshold <- min(bytwo_cse_ev_for_h1$sdtheory)#0.55
bytwo_high_threshold <- max(bytwo_cse_ev_for_h1$sdtheory) #3078
```

## exploratory 2x2 on lohi-lohi
```{r}
lohi_subject_data = filtered_rt %>% 
  filter(prev_num>0,
         current_num>0) %>% 
  group_by(id, congruency,previous_congruency) %>% 
  summarize(mean_rt = mean(rt, na.rm = T)) %>% 
  ungroup()
```
### lohi anova
```{r}
lohi_anova = anova_test(data = lohi_subject_data, formula = mean_rt ~ congruency * previous_congruency + Error(id/(congruency * previous_congruency)))
lohi_anova
```

### lohi model data
```{r}
lohi_model_data = filtered_rt %>% 
  filter(prev_num>0,
         current_num>0) %>% 
  mutate(prev_num = case_when(prev_num == 1 ~ 0,
                   T ~ 1),
         current_num = case_when(current_num == 1 ~ 0,
                   T ~ 1)
         )
```

```{r}
lohi_interaction_model = lmer(rt ~ prev_num * current_num + (1|id), data=lohi_model_data)
lohi_model = summary(lohi_interaction_model)
lohi_model
```
```{r}
Bf(sd = lohi_model$coefficients[8], obtained = lohi_model$coefficients[4], likelihood = "normal",
modeloftheory= "normal", meanoftheory = 0,
scaleoftheory = 14.75, tail = 1, method = "new")
```
```{r}
old_Bf(sd = lohi_model$coefficients[8],
   obtained = lohi_model$coefficients[4],
   dfdata = lohi_model$coefficients[12],
   meanoftheory = 0,
   sdtheory =14.75,#9.7,
   dftheory = 10^10,
   tail = 1)

```


```{r}
loh_range = seq(from=1,to=10000,by=1)
range_test_lohi <- Bf_range(lohi_model$coefficients[8], lohi_model$coefficients[4],
likelihood = "normal",
modeloftheory = "normal",
modeoftheory=0,
sdtheoryrange= loh_range,
tail=1, method = "new")
# find values for which BF > 3
bytwo_cse_ev_for_h1 <- subset(data.frame(range_test_bytwo), BF > 3)
bytwo_low_threshold <- min(bytwo_cse_ev_for_h1$sdtheory)#0.55
bytwo_high_threshold <- max(bytwo_cse_ev_for_h1$sdtheory) #3078
```





# General CSE plot
```{r}
cse_rt_data_no_levels = conflict_level_data %>% 
  group_by(is_congruent, is_prev_congruent) %>% 
  summarize(N = n(),
            mean_rt = mean(as.numeric(rt), na.rm = T),
            sd_rt = sd(rt, na.rm = T),
            se_rt = sd_rt/sqrt(N))

cse_rt_data_no_levels_plot = cse_rt_data_no_levels %>% 
  ggplot()+
  aes(x=as.factor(is_prev_congruent), y=mean_rt, color=as.factor(is_congruent), group=as.factor(is_congruent))+
  geom_point(size=2)+
  geom_path(size=1)+
  geom_errorbar(size=1,aes(ymin=mean_rt-se_rt,
                    ymax=mean_rt+se_rt,
                    width=.2))+
  papaja::theme_apa()+
  labs(x="Previous Congruency",
       y= "Reaction time",
       color="Current Congruency",
       title="Pilot CSE plot")

cse_rt_data_no_levels_plot
```


# Accuracy analysis with plot
```{r}
cse_acc_data = raw_accuracy %>% 
  group_by(congruency, previous_congruency) %>% 
  summarize(N = n(),
            mean_acc = mean(acc, na.rm = T),
            error_rate = 1-mean_acc,
            sd_acc = sd(acc, na.rm = T),
            se_acc = sd_acc/sqrt(N))
```
```{r}
cse_acc_plot = cse_acc_data %>% 
  ggplot()+
  aes(x=factor(previous_congruency, level=c("no_conflict","low_conflict","high_conflict")), y=error_rate, color=congruency, group=congruency)+
  geom_point(size=2)+
  geom_path(size=1)+
  geom_errorbar(size=1,aes(ymin=error_rate-se_acc,
                    ymax=error_rate+se_acc,
                    width=.2))+
  papaja::theme_apa()+
  labs(x="Previous Congruency",
       y= "Mean error_rate",
       color="Current Congruency",
       title="Pilot CSE plot - Accuracy")



cse_acc_plot
```
```{r}
mymodel_acc = lmer(acc ~ congruency * previous_congruency + (1|id), data=raw_accuracy)

summary(mymodel_acc)
anova(mymodel_acc)

reduced_model = lmer(acc ~ congruency + previous_congruency + (1|id), data = raw_accuracy)
anova(reduced_model)

anova(reduced_model,mymodel_acc)

bayesfactor_models(reduced_model, mymodel_acc)
```
```{r}
pairwise_t_test(filter(raw_accuracy, congruency=="low_conflict"), acc ~ previous_congruency, p.adjust.method = "bonferroni")
pairwise_t_test(filter(raw_accuracy, congruency=="no_conflict"), acc ~ previous_congruency, p.adjust.method = "bonferroni")
```